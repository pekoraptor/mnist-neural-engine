{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WSI LAB05 Sztuczne sieci neuronowe\n",
    "### Miłosz Cieśla, Filip Ryniewicz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cele eksperymentów:\n",
    "- Sprawdzenie działania implementacji perceptronu\n",
    "- Znalezienie najlepszych hiperparametrów do rozpoznawania ręcznie pisanych cyfr ze zbioru MNIST\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decyzje projektowe\n",
    "- Funkcja aktywacyjna jest parametryzowana, więc bez problemu można testować różne. My korzystaliśmy z sigmoid'a\n",
    "- Zdecydowaliśmy się połączyć warstwy ukryte z następującymi po nich warstwami aktywacyjnymi w jedną klasę\n",
    "- Dla klasyfikacji binarnej, perceptron tworzy ostatnią warstwę z 1 neuronem, a dla klasyfikacji wieloklasowej - ostatnia warstwa ma tyle neuronów ile klas\n",
    "- W funkcji `fit()` perceptronu dzielimy podany dataset na część trenującą i walidacyjną w zależności od podanego parametru `val_ratio`. Co `val_freq` epok, sprawdzana jest skuteczność funkcji `predict()` na zbiorze walidacyjnym. Jeśli pogorszyła się ona względem poprzedniego sprawdzenia, to trenowanie jest zatrzymywane w celu ograniczenia overfittingu."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Eksperyment - Działanie dla funkcji XOR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "W celu przetestowania działania perceptrona, zdecydowaliśmy się na sprawdzenie go na funkcji XOR. Jest ona dużo mniej obliczeniowo intensywna niż MNIST, więc wykonuje się szybko. Nie jest to eskperyment idealny, ponieważ nie ma jak sprawdzić skuteczności na danych, na których sieć się nie uczyła. W każdym razie, ten eksperyment jest szybkim i prostym sposobem na sprawdzenie skuteczności algorytmu.\n",
    "\n",
    "Tworzymy sieć neuronową posiadającą jedną ukrytą warstwą z 3 neuronami. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-23T15:10:55.108878100Z",
     "start_time": "2023-12-23T15:10:52.734558800Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Input</th>\n",
       "      <th>Predicted</th>\n",
       "      <th>Correct Output</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[0, 0]</td>\n",
       "      <td>[[0.02844655789526437]]</td>\n",
       "      <td>[0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[0, 1]</td>\n",
       "      <td>[[0.9737510283714751]]</td>\n",
       "      <td>[1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[1, 0]</td>\n",
       "      <td>[[0.967580610077897]]</td>\n",
       "      <td>[1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[1, 1]</td>\n",
       "      <td>[[0.02508704987887469]]</td>\n",
       "      <td>[0]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Input                Predicted Correct Output\n",
       "0  [0, 0]  [[0.02844655789526437]]            [0]\n",
       "1  [0, 1]   [[0.9737510283714751]]            [1]\n",
       "2  [1, 0]    [[0.967580610077897]]            [1]\n",
       "3  [1, 1]  [[0.02508704987887469]]            [0]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from report_utils import XOR_test\n",
    "\n",
    "df = XOR_test()\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Wnioski z eksperymentu:\n",
    "Sieć neuronowa dosyć dobrze radzi sobie z funkcją XOR. Przewidziany output jest o ok. 3% inny od prawidłowego, ale nadal 0.97 jest na tyle blisko do 1, że po zaokrągleniu będzie idealna skuteczność. Podejrzewam, że lekka zmiana learning rate lub więcej epok uczących sprawią, że wynik będzie jeszcze dokładniejszy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Eksperyment - Znalezienie najlepszego learning rate dla danych ze zbioru MNIST"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "W celu porównania różnych learning rate, kolejno uczymy sieć neuronową funkcją `fit()` i testujemy jej działanie funkcją `predict()`. Następnie, na wykresie słupkowym przedstawiamy uzyskaną skuteczność dla każdego learning rate.\n",
    "\n",
    "Na początku dzielimy dataset na zbiór trenujący i testowy. W tym eksperymencie nie przeprowadzamy walidacji, ponieważ wczesne stopowanie trenowania mogłoby zaciemnić różnicę, między różnymi learning rates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from report_utils import analyze_learning_rate, plt_accuracy, process_dataset\n",
    "from activations import sigmoid, sigmoid_prime\n",
    "from perceptron import Perceptron\n",
    "\n",
    "X, Y = process_dataset()\n",
    "\n",
    "p = Perceptron(64, 10, 3, 10, sigmoid, sigmoid_prime)\n",
    "\n",
    "learning_rates = [0.0001, 0.001, 0.005, 0.01, 0.05, 0.1, 0.5]\n",
    "acc_arr = analyze_learning_rate(X, Y, p, learning_rates, 500, 0.33)\n",
    "\n",
    "plt_accuracy(learning_rates, acc_arr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Wnioski z eksperymentu:\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
